#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤–∏–¥–µ–æ
–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä—É—Å—Å–∫—É—é —Ä–µ—á—å —á–µ—Ä–µ–∑ Whisper, –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —á–µ—Ä–µ–∑ GPT-5 –∏ –≤—à–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –æ–±—Ä–∞—Ç–Ω–æ
"""

import os
import sys
import re
import argparse
from pathlib import Path
from typing import List, Tuple
import tempfile
import subprocess
from datetime import datetime

# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows
if sys.platform == 'win32':
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –¥–ª—è stdout/stderr
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π Python
    else:
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from openai import OpenAI, AsyncOpenAI
from dotenv import load_dotenv
import asyncio
import shutil

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()


def find_ffmpeg() -> str:
    """
    –ò—â–µ—Ç ffmpeg –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ Windows
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ ffmpeg.exe –∏–ª–∏ 'ffmpeg' –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –≤ PATH
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º PATH
    if shutil.which('ffmpeg'):
        return 'ffmpeg'
    
    # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ Windows
    possible_paths = [
        r'C:\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe',
        os.path.expanduser(r'~\ffmpeg\bin\ffmpeg.exe'),
        r'C:\ProgramData\chocolatey\bin\ffmpeg.exe',
        os.path.expanduser(r'~\scoop\apps\ffmpeg\current\bin\ffmpeg.exe'),
        os.path.expanduser(r'~\scoop\shims\ffmpeg.exe'),
        # –õ–æ–∫–∞–ª—å–Ω–æ –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        os.path.join(os.getcwd(), 'ffmpeg', 'bin', 'ffmpeg.exe'),
        os.path.join(os.getcwd(), 'ffmpeg.exe'),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # –ù–µ –Ω–∞–π–¥–µ–Ω
    return None


def find_ffprobe() -> str:
    """
    –ò—â–µ—Ç ffprobe –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ Windows
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ ffprobe.exe –∏–ª–∏ 'ffprobe' –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –≤ PATH
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º PATH
    if shutil.which('ffprobe'):
        return 'ffprobe'
    
    # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ Windows
    possible_paths = [
        r'C:\ffmpeg\bin\ffprobe.exe',
        r'C:\Program Files\ffmpeg\bin\ffprobe.exe',
        r'C:\Program Files (x86)\ffmpeg\bin\ffprobe.exe',
        os.path.expanduser(r'~\ffmpeg\bin\ffprobe.exe'),
        r'C:\ProgramData\chocolatey\bin\ffprobe.exe',
        os.path.expanduser(r'~\scoop\apps\ffmpeg\current\bin\ffprobe.exe'),
        os.path.expanduser(r'~\scoop\shims\ffprobe.exe'),
        # –õ–æ–∫–∞–ª—å–Ω–æ –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        os.path.join(os.getcwd(), 'ffmpeg', 'bin', 'ffprobe.exe'),
        os.path.join(os.getcwd(), 'ffprobe.exe'),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # –ù–µ –Ω–∞–π–¥–µ–Ω
    return None


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—É—Ç–µ–π –∫ ffmpeg
FFMPEG_PATH = None
FFPROBE_PATH = None


class SubtitleEntry:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å—å—é —Å—É–±—Ç–∏—Ç—Ä–∞"""
    
    def __init__(self, index, start_time: str, end_time: str, text: str):
        self.index = index  # –ú–æ–∂–µ—Ç –±—ã—Ç—å int –∏–ª–∏ str (–¥–ª—è —Å—É–±-–∏–Ω–¥–µ–∫—Å–æ–≤)
        self.start_time = start_time
        self.end_time = end_time
        self.text = text
    
    def __str__(self):
        return f"{self.index}\n{self.start_time} --> {self.end_time}\n{self.text}\n"


def get_audio_duration(audio_path: str) -> float:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
    cmd = [
        FFPROBE_PATH, '-i', audio_path,
        '-show_entries', 'format=duration',
        '-v', 'quiet',
        '-of', 'csv=p=0'
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, check=True)
    return float(result.stdout.strip())


def extract_audio(video_path: str, audio_path: str) -> None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞"""
    print(f"üìπ –ò–∑–≤–ª–µ–∫–∞—é –∞—É–¥–∏–æ –∏–∑ {video_path}...")
    
    cmd = [
        FFMPEG_PATH, '-i', video_path,
        '-vn',  # –±–µ–∑ –≤–∏–¥–µ–æ
        '-acodec', 'libmp3lame',  # –∫–æ–¥–µ–∫ mp3
        '-ab', '128k',  # –±–∏—Ç—Ä–µ–π—Ç (—É–º–µ–Ω—å—à–µ–Ω –¥–æ 128k –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–∞–∑–º–µ—Ä–∞)
        '-ar', '44100',  # sample rate
        '-y',  # –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        audio_path
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"‚úÖ –ê—É–¥–∏–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {audio_path}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e.stderr.decode()}")
        raise


def split_audio(audio_path: str, chunk_duration: int = 600) -> List[str]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–µ 24MB
    chunk_duration: –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞—Å—Ç–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10 –º–∏–Ω—É—Ç)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —á–∞—Å—Ç—è–º
    """
    file_size = os.path.getsize(audio_path)
    max_size = 24 * 1024 * 1024  # 24MB (–æ—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å)
    
    print(f"üìä –†–∞–∑–º–µ—Ä –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: {file_size / 1024 / 1024:.2f}MB")
    
    if file_size <= max_size:
        print(f"‚úÖ –§–∞–π–ª –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç API, —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return [audio_path]
    
    print(f"‚ö†Ô∏è  –§–∞–π–ª –±–æ–ª—å—à–æ–π ({file_size / 1024 / 1024:.1f}MB), —Ä–∞–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏...")
    
    duration = get_audio_duration(audio_path)
    print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {duration / 60:.1f} –º–∏–Ω—É—Ç")
    
    chunks = []
    base_path = audio_path.rsplit('.', 1)[0]
    extension = audio_path.rsplit('.', 1)[1]
    
    num_chunks = int(duration / chunk_duration) + 1
    
    for i in range(num_chunks):
        start_time = i * chunk_duration
        chunk_path = f"{base_path}_part{i+1}.{extension}"
        
        cmd = [
            FFMPEG_PATH, '-i', audio_path,
            '-ss', str(start_time),
            '-t', str(chunk_duration),
            '-acodec', 'copy',
            '-y',
            chunk_path
        ]
        
        subprocess.run(cmd, check=True, capture_output=True)
        chunks.append(chunk_path)
        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ —á–∞—Å—Ç—å {i+1}/{num_chunks}: {chunk_path}")
    
    return chunks


def split_long_subtitle_text(text: str, max_chars_per_line: int = 45) -> str:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º —Å–ª–æ–≤
    –û–ø—Ç–∏–º–∞–ª—å–Ω–æ 45 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫—É
    """
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if len(text) <= max_chars_per_line:
        return text
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å–ª–æ–≤–∞–º
    words = text.split()
    lines = []
    current_line = []
    current_length = 0
    
    for word in words:
        word_length = len(word) + (1 if current_line else 0)  # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞
        if current_length + word_length <= max_chars_per_line:
            current_line.append(word)
            current_length += word_length
        else:
            if current_line:
                lines.append(' '.join(current_line))
            current_line = [word]
            current_length = len(word)
    
    if current_line:
        lines.append(' '.join(current_line))
    
    return '\n'.join(lines)


def split_subtitle_entry(entry: SubtitleEntry, max_lines: int = 2) -> List[SubtitleEntry]:
    """
    –†–∞–∑–¥–µ–ª—è–µ—Ç –¥–ª–∏–Ω–Ω—ã–π SubtitleEntry –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö (–º–∞–∫—Å–∏–º—É–º 2 —Å—Ç—Ä–æ–∫–∏ –∫–∞–∂–¥—ã–π)
    –í—Ä–µ–º—è –¥–µ–ª–∏—Ç—Å—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —á–∞—Å—Ç–µ–π
    """
    # –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –ø–æ 45 —Å–∏–º–≤–æ–ª–æ–≤
    text_with_lines = split_long_subtitle_text(entry.text)
    lines = text_with_lines.split('\n')
    
    # –ï—Å–ª–∏ <= 2 —Å—Ç—Ä–æ–∫ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if len(lines) <= max_lines:
        entry.text = text_with_lines
        return [entry]
    
    # –î–µ–ª–∏–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 2 —Å—Ç—Ä–æ–∫–∏
    parts = []
    for i in range(0, len(lines), max_lines):
        part_lines = lines[i:i + max_lines]
        parts.append('\n'.join(part_lines))
    
    # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è
    def parse_time(time_str: str) -> float:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç HH:MM:SS,mmm –≤ —Å–µ–∫—É–Ω–¥—ã"""
        time_part = time_str.replace(',', '.')
        h, m, s = time_part.split(':')
        return int(h) * 3600 + int(m) * 60 + float(s)
    
    def format_time(seconds: float) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—É–Ω–¥—ã –≤ HH:MM:SS,mmm"""
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = seconds % 60
        return f"{h:02d}:{m:02d}:{s:06.3f}".replace('.', ',')
    
    start_sec = parse_time(entry.start_time)
    end_sec = parse_time(entry.end_time)
    duration = end_sec - start_sec
    
    # –î–µ–ª–∏–º –≤—Ä–µ–º—è –Ω–∞ —á–∞—Å—Ç–∏
    part_duration = duration / len(parts)
    
    result = []
    for i, part_text in enumerate(parts):
        part_start = start_sec + i * part_duration
        part_end = part_start + part_duration
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É–±-–∏–Ω–¥–µ–∫—Å—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä 4, 4.1, 4.2)
        sub_index = entry.index if i == 0 else f"{entry.index}_{i}"
        
        result.append(SubtitleEntry(
            index=sub_index,
            start_time=format_time(part_start),
            end_time=format_time(part_end),
            text=part_text
        ))
    
    return result


def format_timestamp(seconds: float) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—É–Ω–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç SRT (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def transcribe_audio_chunk(audio_path: str, client: OpenAI, offset: float = 0) -> str:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API
    offset: —Å–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ —Ç–∞–π–º–∏–Ω–≥–æ–≤ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç
    """
    file_size = os.path.getsize(audio_path)
    print(f"   üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é —Ñ–∞–π–ª ({file_size / 1024 / 1024:.2f}MB) –≤ Whisper API...", flush=True)
    
    with open(audio_path, 'rb') as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="srt",  # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π SRT!
            language="ru"
        )
    
    print(f"   ‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Whisper API", flush=True)
    
    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∞–π–º–∏–Ω–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–º–µ—â–µ–Ω–∏–µ
    if offset > 0:
        transcript = adjust_srt_timings(transcript, offset)
    
    return transcript


def adjust_srt_timings(srt_content: str, offset_seconds: float) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ –∫–æ –≤—Å–µ–º —Ç–∞–π–º–∏–Ω–≥–∞–º –≤ SRT"""
    from datetime import timedelta
    
    def add_offset(time_str: str) -> str:
        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM:SS,mmm
        h, m, s_ms = time_str.split(':')
        s, ms = s_ms.split(',')
        
        total_seconds = int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000
        total_seconds += offset_seconds
        
        td = timedelta(seconds=total_seconds)
        hours = int(td.total_seconds() // 3600)
        minutes = int((td.total_seconds() % 3600) // 60)
        seconds = int(td.total_seconds() % 60)
        milliseconds = int((td.total_seconds() % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"
    
    lines = srt_content.split('\n')
    adjusted_lines = []
    
    for line in lines:
        if '-->' in line:
            start, end = line.split(' --> ')
            start = add_offset(start.strip())
            end = add_offset(end.strip())
            adjusted_lines.append(f"{start} --> {end}")
        else:
            adjusted_lines.append(line)
    
    return '\n'.join(adjusted_lines)


def transcribe_audio(audio_paths: List[str], client: OpenAI) -> str:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç
    """
    if len(audio_paths) == 1:
        print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API...", flush=True)
        transcript = transcribe_audio_chunk(audio_paths[0], client)
        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞", flush=True)
        return transcript
    
    print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API ({len(audio_paths)} —á–∞—Å—Ç–µ–π)...", flush=True)
    
    all_transcripts = []
    offset = 0
    
    for i, audio_path in enumerate(audio_paths, 1):
        print(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞—Å—Ç—å {i}/{len(audio_paths)}...", flush=True)
        
        transcript = transcribe_audio_chunk(audio_path, client, offset)
        all_transcripts.append(transcript)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —á–∞—Å—Ç–∏
        duration = get_audio_duration(audio_path)
        offset += duration
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—ã
    combined = '\n\n'.join(all_transcripts)
    
    print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞", flush=True)
    return combined


def parse_srt(srt_content: str) -> List[SubtitleEntry]:
    """–ü–∞—Ä—Å–∏—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç –≤ —Å–ø–∏—Å–æ–∫ SubtitleEntry"""
    entries = []
    blocks = srt_content.strip().split('\n\n')
    
    for block in blocks:
        lines = block.strip().split('\n')
        if len(lines) < 3:
            continue
        
        try:
            index = int(lines[0])
            timing = lines[1]
            text = '\n'.join(lines[2:])
            
            # –ü–∞—Ä—Å–∏–º —Ç–∞–π–º–∏–Ω–≥
            match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', timing)
            if match:
                start_time, end_time = match.groups()
                entries.append(SubtitleEntry(index, start_time, end_time, text))
        except (ValueError, IndexError):
            continue
    
    return entries


async def translate_batch_async(
    batch: List[SubtitleEntry], 
    batch_num: int, 
    total_batches: int,
    client: AsyncOpenAI, 
    model: str
) -> List[SubtitleEntry]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –æ–¥–∏–Ω –±–∞—Ç—á —Å—É–±—Ç–∏—Ç—Ä–æ–≤
    –ë–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏ (40-50) –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    """
    print(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á {batch_num}/{total_batches} ({len(batch)} –∑–∞–ø–∏—Å–µ–π)...", flush=True)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
    prompt_lines = []
    for entry in batch:
        prompt_lines.append(f"[{entry.index}] {entry.text}")
    
    system_instruction = """You are a professional subtitle translator. Translate Russian subtitles into natural, conversational English.

CRITICAL RULES:
1. Translate ALL subtitles in the batch - NEVER skip any
2. Keep [number] format for each line
3. TRANSLATE COMPLETE TEXT - do NOT shorten or cut off translations
4. Each translation must contain ALL information from the original Russian text
5. Make translations natural and conversational but COMPLETE
6. Use context from surrounding subtitles for accurate meaning
7. If original is long, translation should be long too - preserve ALL content
8. Output ONLY translations in [number] text format - one line per subtitle

Example:
Input:
[1] –î–æ–±—Ä—ã–π –¥–µ–Ω—å, –∫–æ–ª–ª–µ–≥–∏! –°–µ–≥–æ–¥–Ω—è –º—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º –≤–∞—à–µ–º—É –≤–Ω–∏–º–∞–Ω–∏—é –¥–∏–∑–∞–π–Ω —Ñ–∏—Ç–æ–±–∞—Ä–∞, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–π –Ω–∞ –≤—Ç–æ—Ä–æ–º —ç—Ç–∞–∂–µ.
[2] –ù–∞—á–Ω–µ–º —Å –ø–ª–∞–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è.

Output:
[1] Good afternoon, colleagues! Today we're presenting the design for the phytobar located on the second floor.
[2] Let's start with the layout solution."""
    
    user_input = f"""<subtitles_to_translate>
{chr(10).join(prompt_lines)}
</subtitles_to_translate>

Translate all subtitles above into English. Output format: [number] translated_text"""
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Chat Completions API
        messages = [
            {"role": "system", "content": system_instruction},
            {"role": "user", "content": user_input}
        ]
        
        api_params = {
            "model": model,
            "messages": messages,
            "temperature": 0.7
        }
        
        # GPT-5 —Ç—Ä–µ–±—É–µ—Ç temperature=1 –∏ max_completion_tokens (–±–æ–ª—å—à–µ —Ç.–∫. reasoning —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è)
        if model.startswith('gpt-5') or model.startswith('o1') or model.startswith('o3'):
            api_params["temperature"] = 1.0
            api_params["max_completion_tokens"] = 16000  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è reasoning + –æ—Ç–≤–µ—Ç
        else:
            api_params["max_tokens"] = 4000
        
        response = await client.chat.completions.create(**api_params)
        
        translated_text = response.choices[0].message.content
        if translated_text is None:
            translated_text = ""
        translated_text = translated_text.strip()
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        translated_lines = translated_text.split('\n')
        translation_map = {}
        
        for line in translated_lines:
            match = re.match(r'\[(\d+)\]\s*(.+)', line.strip())
            if match:
                idx, text = match.groups()
                translation_map[int(idx)] = text.strip()
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ —Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        translated_batch = []
        untranslated = []
        
        for entry in batch:
            translated_text = translation_map.get(entry.index)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–µ—Ä–µ–≤–æ–¥ –ø–æ–ª—É—á–µ–Ω –ò –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É
            if translated_text and not re.search(r'[–ê-–Ø–∞-—è–Å—ë]', translated_text):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∫ –µ—Å—Ç—å (—Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –±—É–¥–µ—Ç –≤ post-processing)
                translated_batch.append(
                    SubtitleEntry(entry.index, entry.start_time, entry.end_time, translated_text)
                )
            else:
                # –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É - –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ –ø–æ–º–µ—á–∞–µ–º
                translated_batch.append(entry)
                untranslated.append(entry.index)
        
        if untranslated:
            print(f"   ‚ö†Ô∏è  –ë–∞—Ç—á {batch_num}: –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ {len(untranslated)} –∑–∞–ø–∏—Å–µ–π: {untranslated[:5]}{'...' if len(untranslated) > 5 else ''}", flush=True)
        else:
            print(f"   ‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches} –∑–∞–≤–µ—Ä—à–µ–Ω", flush=True)
        
        return translated_batch
    
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}: {e}", flush=True)
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
        return batch


async def translate_subtitles_async(entries: List[SubtitleEntry], api_key: str, model: str = "gpt-4o-mini") -> List[SubtitleEntry]:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∏ —É–ª—É—á—à–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã —á–µ—Ä–µ–∑ GPT –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –±–∞—Ç—á–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
    """
    print(f"üåê –ü–µ—Ä–µ–≤–æ–∂—É –∏ —É–ª—É—á—à–∞—é —Å—É–±—Ç–∏—Ç—Ä—ã —á–µ—Ä–µ–∑ {model} (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)...", flush=True)
    
    # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
    async_client = AsyncOpenAI(api_key=api_key)
    
    batch_size = 40  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞!
    total_batches = (len(entries) + batch_size - 1) // batch_size
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö –±–∞—Ç—á–µ–π
    tasks = []
    for i in range(0, len(entries), batch_size):
        batch = entries[i:i + batch_size]
        batch_num = i // batch_size + 1
        task = translate_batch_async(batch, batch_num, total_batches, async_client, model)
        tasks.append(task)
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é {total_batches} –±–∞—Ç—á–µ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...", flush=True)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(*tasks)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    translated_entries = []
    for batch_result in results:
        translated_entries.extend(batch_result)
    
    # POST-PROCESSING: —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π (–º–∞–∫—Å–∏–º—É–º 2 —Å—Ç—Ä–æ–∫–∏ –∫–∞–∂–¥–∞—è)
    print(f"üìê Post-processing: —Ä–∞–∑–±–∏–≤–∞—é –¥–ª–∏–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ —á–∞—Å—Ç–∏...", flush=True)
    final_entries = []
    for entry in translated_entries:
        # –†–∞–∑–¥–µ–ª—è–µ–º –µ—Å–ª–∏ > 2 —Å—Ç—Ä–æ–∫, –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
        parts = split_subtitle_entry(entry, max_lines=2)
        final_entries.extend(parts)
    
    translated_entries = final_entries
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ
    untranslated_count = sum(1 for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text))
    
    if untranslated_count > 0:
        print(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: {untranslated_count} –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞–ª–∏—Å—å –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º–∏!", flush=True)
        print(f"   –ó–∞–ø—É—Å–∫–∞—é –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ (–±–∞—Ç—á–∏ –ø–æ 10)...", flush=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        to_retry = [e for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text)]
        
        # –ü–æ–≤—Ç–æ—Ä–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏–º –±–∞—Ç—á–∞–º–∏ –ø–æ 30 (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç)
        retry_tasks = []
        for i in range(0, len(to_retry), 30):
            retry_batch = to_retry[i:i + 30]
            batch_num = i // 30 + 1
            task = translate_batch_async(retry_batch, batch_num, (len(to_retry) + 29) // 30, async_client, model)
            retry_tasks.append(task)
        
        retry_results = await asyncio.gather(*retry_tasks)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        retry_map = {}
        for batch_result in retry_results:
            for entry in batch_result:
                retry_map[entry.index] = entry
        
        # –ó–∞–º–µ–Ω—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å–ø–∏—Å–∫–µ
        translated_entries = [retry_map.get(e.index, e) for e in translated_entries]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ retry
        after_retry1 = sum(1 for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text))
        
        if after_retry1 > 0:
            print(f"‚ö†Ô∏è  –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ retry –æ—Å—Ç–∞–ª–æ—Å—å {after_retry1} –∑–∞–ø–∏—Å–µ–π", flush=True)
            print(f"   –ó–∞–ø—É—Å–∫–∞—é –≤—Ç–æ—Ä–æ–π retry (–±–∞—Ç—á–∏ –ø–æ 5, –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)...", flush=True)
            
            # –í—Ç–æ—Ä–æ–π retry - –±–∞—Ç—á–∏ –ø–æ 15 (–ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)
            to_retry2 = [e for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text)]
            retry_tasks2 = []
            
            for i in range(0, len(to_retry2), 15):
                retry_batch = to_retry2[i:i + 15]
                batch_num = i // 15 + 1
                task = translate_batch_async(retry_batch, batch_num, (len(to_retry2) + 14) // 15, async_client, model)
                retry_tasks2.append(task)
            
            retry_results2 = await asyncio.gather(*retry_tasks2)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–Ω–æ–≤–∞
            retry_map2 = {}
            for batch_result in retry_results2:
                for entry in batch_result:
                    retry_map2[entry.index] = entry
            
            translated_entries = [retry_map2.get(e.index, e) for e in translated_entries]
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            final_untranslated = sum(1 for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text))
            if final_untranslated > 0:
                print(f"‚ö†Ô∏è  –ü–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–≥–æ retry –æ—Å—Ç–∞–ª–æ—Å—å {final_untranslated} –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π", flush=True)
                print(f"   –ò–Ω–¥–µ–∫—Å—ã: {[e.index for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text)]}", flush=True)
            else:
                print(f"‚úÖ –ü–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–≥–æ retry –≤—Å–µ –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã!", flush=True)
        else:
            print(f"‚úÖ –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ retry –≤—Å–µ –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã!", flush=True)
    
    print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_batches} –±–∞—Ç—á–µ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)", flush=True)
    return translated_entries


def translate_subtitles(entries: List[SubtitleEntry], api_key: str, model: str = "gpt-4o-mini") -> List[SubtitleEntry]:
    """
    –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
    """
    # –î–ª—è Windows: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É event loop
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    try:
        return asyncio.run(translate_subtitles_async(entries, api_key, model))
    finally:
        # –ü–æ–¥–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –∑–∞–∫—Ä—ã—Ç–∏—è event loop –Ω–∞ Windows
        if sys.platform == 'win32':
            import warnings
            warnings.filterwarnings('ignore', category=RuntimeWarning, message='.*Event loop is closed.*')


def save_srt(entries: List[SubtitleEntry], output_path: str) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –≤ SRT —Ñ–∞–π–ª"""
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å—É–±—Ç–∏—Ç—Ä—ã –≤ {output_path}...")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(str(entry) + '\n')
    
    print(f"‚úÖ –°—É–±—Ç–∏—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")


def burn_subtitles(video_path: str, srt_path: str, output_path: str) -> None:
    """–í—à–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –≤ –≤–∏–¥–µ–æ (hardcoded)"""
    print(f"üé¨ –í—à–∏–≤–∞—é —Å—É–±—Ç–∏—Ç—Ä—ã –≤ –≤–∏–¥–µ–æ...")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏ –¥–ª—è ffmpeg (–æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è Windows)
    srt_path_escaped = srt_path.replace('\\', '/').replace(':', '\\:')
    
    cmd = [
        FFMPEG_PATH, '-i', video_path,
        '-vf', f"subtitles='{srt_path_escaped}':force_style='FontName=Arial,FontSize=20,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,BorderStyle=3,MarginV=30'",
        '-c:a', 'copy',  # –∫–æ–ø–∏—Ä—É–µ–º –∞—É–¥–∏–æ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        '-y',
        output_path
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"‚úÖ –í–∏–¥–µ–æ —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏: {output_path}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—à–∏–≤–∞–Ω–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤: {e.stderr.decode()}")
        raise


def main():
    parser = argparse.ArgumentParser(
        description='–£–ª—É—á—à–µ–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —á–µ—Ä–µ–∑ Whisper + –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ GPT',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python subtitle_improver.py video.mp4
  python subtitle_improver.py video.mp4 --model gpt-4o
  python subtitle_improver.py video.mp4 --skip-burn

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
  OPENAI_API_KEY - –≤–∞—à API –∫–ª—é—á OpenAI (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        """
    )
    
    parser.add_argument('video', help='–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É')
    parser.add_argument('--model', 
                        choices=['gpt-4o-mini', 'gpt-4o', 'gpt-5'],
                        default='gpt-4o',
                        help='–ú–æ–¥–µ–ª—å GPT –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: gpt-4o, –º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –∑–∞–¥–∞—Ç—å –≤ .env —Ñ–∞–π–ª–µ)')
    parser.add_argument('--skip-burn', action='store_true',
                        help='–ù–µ –≤—à–∏–≤–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –≤ –≤–∏–¥–µ–æ, —Ç–æ–ª—å–∫–æ —Å–æ–∑–¥–∞—Ç—å .srt —Ñ–∞–π–ª')
    parser.add_argument('--step', 
                        choices=['all', 'transcribe', 'translate', 'burn'],
                        default='all',
                        help='–ö–∞–∫–æ–π —ç—Ç–∞–ø –≤—ã–ø–æ–ª–Ω–∏—Ç—å: all (–≤—Å–µ), transcribe (—Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è), translate (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥), burn (—Ç–æ–ª—å–∫–æ –≤—à–∏–≤–∞–Ω–∏–µ)')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY")
        print()
        print("   –†–µ—à–µ–Ω–∏–µ 1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): –°–æ–∑–¥–∞–π—Ç–µ .env —Ñ–∞–π–ª")
        print("   1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ env.example –≤ .env")
        print("   2. –û—Ç–∫—Ä–æ–π—Ç–µ .env –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à API –∫–ª—é—á")
        print()
        print("   –†–µ—à–µ–Ω–∏–µ 2: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        print("   PowerShell: $env:OPENAI_API_KEY=\"your-api-key\"")
        print("   CMD:        set OPENAI_API_KEY=your-api-key")
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å: –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤, –∏–∑ .env –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    model = args.model or os.environ.get('GPT_MODEL', 'gpt-4o-mini')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ
    video_path = Path(args.video)
    if not video_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.video}")
        sys.exit(1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Ç–∏ –∫ ffmpeg –∏ ffprobe (—Ç–æ–ª—å–∫–æ –¥–ª—è —ç—Ç–∞–ø–æ–≤ –∫–æ—Ç–æ—Ä—ã–º –æ–Ω–∏ –Ω—É–∂–Ω—ã)
    if args.step in ['all', 'transcribe', 'burn']:
        global FFMPEG_PATH, FFPROBE_PATH
        
        FFMPEG_PATH = find_ffmpeg()
        FFPROBE_PATH = find_ffprobe()
        
        if not FFMPEG_PATH or not FFPROBE_PATH:
            print("‚ùå –û—à–∏–±–∫–∞: ffmpeg/ffprobe –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            print()
            print("   üì• –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ffmpeg –æ–¥–Ω–∏–º –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤:")
            print()
            print("   –°–ø–æ—Å–æ–± 1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): Chocolatey")
            print("   1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Chocolatey: https://chocolatey.org/install")
            print("   2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ PowerShell –æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
            print("   3. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: choco install ffmpeg")
            print()
            print("   –°–ø–æ—Å–æ–± 2: Scoop")
            print("   1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Scoop: https://scoop.sh")
            print("   2. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: scoop install ffmpeg")
            print()
            print("   –°–ø–æ—Å–æ–± 3: –í—Ä—É—á–Ω—É—é")
            print("   1. –°–∫–∞—á–∞–π—Ç–µ: https://www.gyan.dev/ffmpeg/builds/")
            print("   2. –†–∞—Å–ø–∞–∫—É–π—Ç–µ –≤ C:\\ffmpeg")
            print("   3. –î–æ–±–∞–≤—å—Ç–µ C:\\ffmpeg\\bin –≤ PATH")
            print()
            print("   üìç –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∏—Å–∫–∞–ª–∞ ffmpeg –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –º–µ—Å—Ç–∞—Ö:")
            print("      - –°–∏—Å—Ç–µ–º–Ω—ã–π PATH")
            print("      - C:\\ffmpeg\\bin\\")
            print("      - C:\\Program Files\\ffmpeg\\bin\\")
            print(f"      - {os.path.expanduser('~\\ffmpeg\\bin\\')}")
            print("      - C:\\ProgramData\\chocolatey\\bin\\")
            print(f"      - {os.path.expanduser('~\\scoop\\apps\\ffmpeg\\')}")
            print(f"      - {os.getcwd()} (—Ç–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞)")
            print()
            sys.exit(1)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω ffmpeg: {FFMPEG_PATH}")
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω ffprobe: {FFPROBE_PATH}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç
    client = OpenAI(api_key=api_key)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    base_name = video_path.stem
    outputs_dir = video_path.parent / "outputs" / base_name
    outputs_dir.mkdir(parents=True, exist_ok=True)
    
    # –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ—Ä–Ω–µ –ø–∞–ø–∫–∏ –≤–∏–¥–µ–æ
    russian_srt = outputs_dir / "russian.srt"
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É —Å timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = outputs_dir / f"run_{timestamp}"
    run_dir.mkdir(parents=True, exist_ok=True)
    
    output_srt = run_dir / "improved.srt"
    output_video = run_dir / "subtitled.mp4"
    
    step = args.step
    
    print(f"üìÅ –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {run_dir}", flush=True)
    
    print(f"\n{'='*60}", flush=True)
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ: {video_path.name}", flush=True)
    print(f"{'='*60}\n", flush=True)
    
    try:
        # ========================================
        # –≠–¢–ê–ü 1: –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø (Whisper)
        # ========================================
        if step in ['all', 'transcribe']:
            if russian_srt.exists():
                print(f"‚ÑπÔ∏è  –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç: {russian_srt}")
                print(f"   –£–¥–∞–ª–∏—Ç–µ —Ñ–∞–π–ª –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å")
            else:
                # –®–∞–≥ 1: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ
                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_audio:
                    audio_path = tmp_audio.name
                
                extract_audio(str(video_path), audio_path)
                
                # –®–∞–≥ 2: –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                audio_chunks = split_audio(audio_path)
                
                # –®–∞–≥ 3: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ Whisper (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT)
                srt_content = transcribe_audio(audio_chunks, client)
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã
                for chunk in audio_chunks:
                    if os.path.exists(chunk):
                        os.unlink(chunk)
                if audio_path not in audio_chunks and os.path.exists(audio_path):
                    os.unlink(audio_path)
                
                # –ü–∞—Ä—Å–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã
                print(f"üìù –ü–∞—Ä—Å–∏–Ω–≥ —Å—É–±—Ç–∏—Ç—Ä–æ–≤...", flush=True)
                russian_entries = parse_srt(srt_content)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã –≤ {russian_srt}...", flush=True)
                save_srt(russian_entries, str(russian_srt))
                print(f"‚úÖ –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {len(russian_entries)} –∑–∞–ø–∏—Å–µ–π", flush=True)
        
        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è - –≤—ã—Ö–æ–¥–∏–º
        if step == 'transcribe':
            print(f"\n{'='*60}", flush=True)
            print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", flush=True)
            print(f"{'='*60}", flush=True)
            print(f"üìÑ –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {russian_srt.relative_to(video_path.parent)}", flush=True)
            print(f"\n–î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:", flush=True)
            print(f"  python subtitle_improver.py {args.video} --step translate\n", flush=True)
            return
        
        # ========================================
        # –≠–¢–ê–ü 2: –ü–ï–†–ï–í–û–î (GPT)
        # ========================================
        if step in ['all', 'translate']:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã
            if not russian_srt.exists():
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ (–¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏)
                old_russian_srt = video_path.parent / f"{base_name}_russian.srt"
                if old_russian_srt.exists():
                    print(f"‚ÑπÔ∏è  –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ø–µ—Ä–µ–º–µ—â–∞—é –≤ –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...", flush=True)
                    russian_srt.parent.mkdir(parents=True, exist_ok=True)
                    old_russian_srt.rename(russian_srt)
                    print(f"‚úÖ –§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤: {russian_srt.relative_to(video_path.parent)}", flush=True)
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {russian_srt} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    print(f"   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python subtitle_improver.py {args.video} --step transcribe")
                    sys.exit(1)
            
            print(f"üìñ –ó–∞–≥—Ä—É–∂–∞—é —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ {russian_srt}...", flush=True)
            with open(russian_srt, 'r', encoding='utf-8') as f:
                srt_content = f.read()
            
            # –ü–∞—Ä—Å–∏–º SRT
            print(f"üìù –ü–∞—Ä—Å–∏–Ω–≥ —Å—É–±—Ç–∏—Ç—Ä–æ–≤...", flush=True)
            russian_entries = parse_srt(srt_content)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(russian_entries)} –∑–∞–ø–∏—Å–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤", flush=True)
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —á–µ—Ä–µ–∑ GPT (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ!)
            translated_entries = translate_subtitles(russian_entries, api_key, model)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã
            save_srt(translated_entries, str(output_srt))
        
        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥ - –≤—ã—Ö–æ–¥–∏–º
        if step == 'translate':
            print(f"\n{'='*60}", flush=True)
            print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!", flush=True)
            print(f"{'='*60}", flush=True)
            print(f"üìÅ –ü–∞–ø–∫–∞: {run_dir.relative_to(video_path.parent)}", flush=True)
            print(f"üìÑ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {output_srt.name}", flush=True)
            print(f"\n–î–ª—è –≤—à–∏–≤–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ:", flush=True)
            print(f"  python subtitle_improver.py {args.video} --step burn\n", flush=True)
            return
        
        # ========================================
        # –≠–¢–ê–ü 3: –í–®–ò–í–ê–ù–ò–ï (ffmpeg)
        # ========================================
        if step in ['all', 'burn']:
            # –î–ª—è burn –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π run —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏
            if step == 'burn' and not output_srt.exists():
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞–ø–∫—É run_* —Å improved.srt
                run_dirs = sorted(outputs_dir.glob("run_*/improved.srt"))
                if run_dirs:
                    latest_srt = run_dirs[-1]
                    print(f"üìñ –ò—Å–ø–æ–ª—å–∑—É—é —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞: {latest_srt.parent.name}", flush=True)
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É –¥–ª—è burn
                    output_srt = latest_srt  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
                    output_video = latest_srt.parent / "subtitled.mp4"
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã")
                    print(f"   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python subtitle_improver.py {args.video} --step translate")
                    sys.exit(1)
            
            if args.skip_burn:
                print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞—é –≤—à–∏–≤–∞–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (--skip-burn)", flush=True)
            else:
                burn_subtitles(str(video_path), str(output_srt), str(output_video))
        
        # –ò—Ç–æ–≥–∏
        print(f"\n{'='*60}", flush=True)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", flush=True)
        print(f"{'='*60}", flush=True)
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {run_dir.relative_to(video_path.parent)}", flush=True)
        print(f"", flush=True)
        if russian_srt.exists():
            print(f"   üìÑ –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {russian_srt.relative_to(video_path.parent)}", flush=True)
        if output_srt.exists():
            print(f"   üìÑ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {output_srt.relative_to(outputs_dir)}", flush=True)
        if not args.skip_burn and output_video.exists():
            print(f"   üé¨ –í–∏–¥–µ–æ —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏: {output_video.relative_to(outputs_dir)}", flush=True)
        print(f"\n", flush=True)
        
    except KeyboardInterrupt:
        print(f"\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

