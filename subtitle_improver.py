#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤–∏–¥–µ–æ
–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä—É—Å—Å–∫—É—é —Ä–µ—á—å —á–µ—Ä–µ–∑ Whisper, –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —á–µ—Ä–µ–∑ GPT-5 –∏ –≤—à–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –æ–±—Ä–∞—Ç–Ω–æ
"""

import os
import sys
import re
import argparse
from pathlib import Path
from typing import List, Tuple
import tempfile
import subprocess
from datetime import datetime

# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è Windows
if sys.platform == 'win32':
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –¥–ª—è stdout/stderr
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π Python
    else:
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from openai import OpenAI, AsyncOpenAI
from dotenv import load_dotenv
import asyncio
import shutil

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()


def find_ffmpeg() -> str:
    """
    –ò—â–µ—Ç ffmpeg –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ Windows
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ ffmpeg.exe –∏–ª–∏ 'ffmpeg' –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –≤ PATH
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º PATH
    if shutil.which('ffmpeg'):
        return 'ffmpeg'
    
    # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ Windows
    possible_paths = [
        r'C:\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe',
        os.path.expanduser(r'~\ffmpeg\bin\ffmpeg.exe'),
        r'C:\ProgramData\chocolatey\bin\ffmpeg.exe',
        os.path.expanduser(r'~\scoop\apps\ffmpeg\current\bin\ffmpeg.exe'),
        os.path.expanduser(r'~\scoop\shims\ffmpeg.exe'),
        # –õ–æ–∫–∞–ª—å–Ω–æ –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        os.path.join(os.getcwd(), 'ffmpeg', 'bin', 'ffmpeg.exe'),
        os.path.join(os.getcwd(), 'ffmpeg.exe'),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # –ù–µ –Ω–∞–π–¥–µ–Ω
    return None


def find_ffprobe() -> str:
    """
    –ò—â–µ—Ç ffprobe –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö –Ω–∞ Windows
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ ffprobe.exe –∏–ª–∏ 'ffprobe' –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –≤ PATH
    """
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º PATH
    if shutil.which('ffprobe'):
        return 'ffprobe'
    
    # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ Windows
    possible_paths = [
        r'C:\ffmpeg\bin\ffprobe.exe',
        r'C:\Program Files\ffmpeg\bin\ffprobe.exe',
        r'C:\Program Files (x86)\ffmpeg\bin\ffprobe.exe',
        os.path.expanduser(r'~\ffmpeg\bin\ffprobe.exe'),
        r'C:\ProgramData\chocolatey\bin\ffprobe.exe',
        os.path.expanduser(r'~\scoop\apps\ffmpeg\current\bin\ffprobe.exe'),
        os.path.expanduser(r'~\scoop\shims\ffprobe.exe'),
        # –õ–æ–∫–∞–ª—å–Ω–æ –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        os.path.join(os.getcwd(), 'ffmpeg', 'bin', 'ffprobe.exe'),
        os.path.join(os.getcwd(), 'ffprobe.exe'),
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # –ù–µ –Ω–∞–π–¥–µ–Ω
    return None


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—É—Ç–µ–π –∫ ffmpeg
FFMPEG_PATH = None
FFPROBE_PATH = None


class SubtitleEntry:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å—å—é —Å—É–±—Ç–∏—Ç—Ä–∞"""
    
    def __init__(self, index, start_time: str, end_time: str, text: str):
        self.index = index  # –ú–æ–∂–µ—Ç –±—ã—Ç—å int –∏–ª–∏ str (–¥–ª—è —Å—É–±-–∏–Ω–¥–µ–∫—Å–æ–≤)
        self.start_time = start_time
        self.end_time = end_time
        self.text = text
    
    def __str__(self):
        return f"{self.index}\n{self.start_time} --> {self.end_time}\n{self.text}\n"


def get_audio_duration(audio_path: str) -> float:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
    cmd = [
        FFPROBE_PATH, '-i', audio_path,
        '-show_entries', 'format=duration',
        '-v', 'quiet',
        '-of', 'csv=p=0'
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, check=True)
    return float(result.stdout.strip())


def extract_audio(video_path: str, audio_path: str) -> None:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞"""
    print(f"üìπ –ò–∑–≤–ª–µ–∫–∞—é –∞—É–¥–∏–æ –∏–∑ {video_path}...")
    
    cmd = [
        FFMPEG_PATH, '-i', video_path,
        '-vn',  # –±–µ–∑ –≤–∏–¥–µ–æ
        '-acodec', 'libmp3lame',  # –∫–æ–¥–µ–∫ mp3
        '-ab', '128k',  # –±–∏—Ç—Ä–µ–π—Ç (—É–º–µ–Ω—å—à–µ–Ω –¥–æ 128k –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–∞–∑–º–µ—Ä–∞)
        '-ar', '44100',  # sample rate
        '-y',  # –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        audio_path
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"‚úÖ –ê—É–¥–∏–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {audio_path}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e.stderr.decode()}")
        raise


def split_audio(audio_path: str, target_chunk_size_mb: float = 12.0) -> List[str]:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–µ 24MB
    –£–º–Ω–æ –≤—ã—á–∏—Å–ª—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∏—Ç—Ä–µ–π—Ç–∞, —á—Ç–æ–±—ã –∫–∞–∂–¥–∞—è —á–∞—Å—Ç—å –±—ã–ª–∞ ~12MB
    target_chunk_size_mb: —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ –ú–ë (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 12MB –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —á–∞—Å—Ç—è–º
    """
    file_size = os.path.getsize(audio_path)
    max_size = 24 * 1024 * 1024  # 24MB (–ª–∏–º–∏—Ç API)
    
    print(f"üìä –†–∞–∑–º–µ—Ä –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: {file_size / 1024 / 1024:.2f}MB")
    
    if file_size <= max_size:
        print(f"‚úÖ –§–∞–π–ª –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç API, —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return [audio_path]
    
    print(f"‚ö†Ô∏è  –§–∞–π–ª –±–æ–ª—å—à–æ–π ({file_size / 1024 / 1024:.1f}MB), —Ä–∞–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏...")
    
    duration = get_audio_duration(audio_path)
    print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: {duration / 60:.1f} –º–∏–Ω—É—Ç")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –±–∏—Ç—Ä–µ–π—Ç (–±–∞–π—Ç/—Å–µ–∫—É–Ω–¥–∞) –∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞–Ω–∫–∞
    bitrate_bytes_per_sec = file_size / duration
    target_chunk_bytes = target_chunk_size_mb * 1024 * 1024
    chunk_duration = int(target_chunk_bytes / bitrate_bytes_per_sec)
    
    # –ú–∏–Ω–∏–º—É–º 5 –º–∏–Ω—É—Ç, –º–∞–∫—Å–∏–º—É–º 15 –º–∏–Ω—É—Ç –Ω–∞ —á–∞–Ω–∫
    chunk_duration = max(300, min(chunk_duration, 900))
    
    print(f"   –ë–∏—Ç—Ä–µ–π—Ç: {bitrate_bytes_per_sec * 8 / 1000:.0f} kbps")
    print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∞–Ω–∫–∞: {chunk_duration / 60:.1f} –º–∏–Ω—É—Ç (~{chunk_duration * bitrate_bytes_per_sec / 1024 / 1024:.1f}MB)")
    print(f"   üí° –ú–µ–Ω—å—à–∏–µ —á–∞–Ω–∫–∏ = –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ Whisper API", flush=True)
    
    chunks = []
    base_path = audio_path.rsplit('.', 1)[0]
    extension = audio_path.rsplit('.', 1)[1]
    
    num_chunks = int(duration / chunk_duration) + (1 if duration % chunk_duration > 0 else 0)
    print(f"   –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–æ {num_chunks} —á–∞—Å—Ç–µ–π")
    
    for i in range(num_chunks):
        start_time = i * chunk_duration
        chunk_path = f"{base_path}_part{i+1}.{extension}"
        
        cmd = [
            FFMPEG_PATH, '-i', audio_path,
            '-ss', str(start_time),
            '-t', str(chunk_duration),
            '-acodec', 'copy',
            '-y',
            chunk_path
        ]
        
        subprocess.run(cmd, check=True, capture_output=True)
        
        chunk_size = os.path.getsize(chunk_path)
        chunks.append(chunk_path)
        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ —á–∞—Å—Ç—å {i+1}/{num_chunks}: {chunk_size / 1024 / 1024:.1f}MB")
    
    return chunks


def split_long_subtitle_text(text: str, max_chars_per_line: int = 45) -> str:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º —Å–ª–æ–≤
    –û–ø—Ç–∏–º–∞–ª—å–Ω–æ 45 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å—Ç—Ä–æ–∫—É
    """
    # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if len(text) <= max_chars_per_line:
        return text
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å–ª–æ–≤–∞–º
    words = text.split()
    lines = []
    current_line = []
    current_length = 0
    
    for word in words:
        word_length = len(word) + (1 if current_line else 0)  # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞
        if current_length + word_length <= max_chars_per_line:
            current_line.append(word)
            current_length += word_length
        else:
            if current_line:
                lines.append(' '.join(current_line))
            current_line = [word]
            current_length = len(word)
    
    if current_line:
        lines.append(' '.join(current_line))
    
    return '\n'.join(lines)


def split_subtitle_entry(entry: SubtitleEntry, max_lines: int = 2) -> List[SubtitleEntry]:
    """
    –†–ï–ö–£–†–°–ò–í–ù–ê–Ø —Ä–∞–∑–±–∏–≤–∫–∞: –¥–µ–ª–∏–º —Ç–µ–∫—Å—Ç –ü–û–ü–û–õ–ê–ú –ø–æ —Å–ª–æ–≤–∞–º, –≤—Ä–µ–º—è –ü–†–û–ü–û–†–¶–ò–û–ù–ê–õ–¨–ù–û
    –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–µ–ª–∏—Ç—å –ø–æ–∫–∞ –≤—Å–µ —á–∞—Å—Ç–∏ –Ω–µ –±—É–¥—É—Ç <= max_lines —Å—Ç—Ä–æ–∫
    """
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
    def parse_time(time_str: str) -> float:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç HH:MM:SS,mmm –≤ —Å–µ–∫—É–Ω–¥—ã"""
        time_part = time_str.replace(',', '.')
        h, m, s = time_part.split(':')
        return int(h) * 3600 + int(m) * 60 + float(s)
    
    def format_time(seconds: float) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—É–Ω–¥—ã –≤ HH:MM:SS,mmm"""
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = seconds % 60
        return f"{h:02d}:{m:02d}:{s:06.3f}".replace('.', ',')
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç (—Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –ø–æ 45 —Å–∏–º–≤–æ–ª–æ–≤)
    text_with_lines = split_long_subtitle_text(entry.text)
    lines = text_with_lines.split('\n')
    
    # –ï—Å–ª–∏ <= 2 —Å—Ç—Ä–æ–∫ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if len(lines) <= max_lines:
        entry.text = text_with_lines
        return [entry]
    
    # –ï—Å–ª–∏ > 2 —Å—Ç—Ä–æ–∫ - –¥–µ–ª–∏–º –ü–û–ü–û–õ–ê–ú (—Å–ª–æ–≤–∞ + –≤—Ä–µ–º—è)
    words = entry.text.split()
    
    # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–π —Ä–µ–∫—É—Ä—Å–∏–∏: –µ—Å–ª–∏ —Å–ª–æ–≤ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ
    if len(words) < 2:
        entry.text = text_with_lines
        return [entry]
    
    # –î–µ–ª–∏–º —Å–ª–æ–≤–∞ –ü–û–ü–û–õ–ê–ú
    mid = len(words) // 2
    first_half_words = words[:mid]
    second_half_words = words[mid:]
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–ª–æ–≤–∏–Ω—ã
    first_text = ' '.join(first_half_words)
    second_text = ' '.join(second_half_words)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
    start_sec = parse_time(entry.start_time)
    end_sec = parse_time(entry.end_time)
    duration = end_sec - start_sec
    
    first_len = len(first_text)
    second_len = len(second_text)
    total_len = first_len + second_len
    
    # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
    if total_len == 0:
        entry.text = text_with_lines
        return [entry]
    
    # –í—Ä–µ–º—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
    first_duration = duration * (first_len / total_len)
    split_time = start_sec + first_duration
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–µ –ø–æ–ª–æ–≤–∏–Ω—ã
    first_entry = SubtitleEntry(
        index=entry.index,
        start_time=entry.start_time,
        end_time=format_time(split_time),
        text=first_text
    )
    
    second_entry = SubtitleEntry(
        index=f"{entry.index}_1",
        start_time=format_time(split_time),
        end_time=entry.end_time,
        text=second_text
    )
    
    # –†–ï–ö–£–†–°–ò–í–ù–û –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–æ–ª–æ–≤–∏–Ω—É
    first_parts = split_subtitle_entry(first_entry, max_lines)
    second_parts = split_subtitle_entry(second_entry, max_lines)
    
    # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤–æ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ
    # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ —Ä–∞–∑–±–∏–ª–∞—Å—å –Ω–∞ N —á–∞—Å—Ç–µ–π, –≤—Ç–æ—Ä–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å index_N
    if len(first_parts) > 1 or len(second_parts) > 1:
        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤–æ –≤—Ç–æ—Ä–æ–π —á–∞—Å—Ç–∏
        for i, part in enumerate(second_parts):
            if i == 0:
                part.index = f"{entry.index}_{len(first_parts)}"
            else:
                part.index = f"{entry.index}_{len(first_parts) + i}"
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    return first_parts + second_parts


def format_timestamp(seconds: float) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—É–Ω–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç SRT (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def transcribe_audio_chunk(audio_path: str, client: OpenAI, offset: float = 0) -> str:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
    offset: —Å–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ —Ç–∞–π–º–∏–Ω–≥–æ–≤ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç
    """
    file_size = os.path.getsize(audio_path)
    duration_minutes = get_audio_duration(audio_path) / 60
    estimated_time = duration_minutes * 0.3  # –ü—Ä–∏–º–µ—Ä–Ω–æ 18 —Å–µ–∫—É–Ω–¥ –Ω–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ
    
    print(f"   üì§ –û—Ç–ø—Ä–∞–≤–ª—è—é —Ñ–∞–π–ª ({file_size / 1024 / 1024:.2f}MB, ~{duration_minutes:.1f} –º–∏–Ω) –≤ Whisper API...", flush=True)
    print(f"   ‚è≥ –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: ~{estimated_time:.0f} —Å–µ–∫—É–Ω–¥...", flush=True)
    print(f"   üí° –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ, Whisper –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ...", flush=True)
    
    with open(audio_path, 'rb') as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="srt",  # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π SRT!
            language="ru",
            timeout=600.0  # 10 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º
        )
    
    print(f"   ‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Whisper API", flush=True)
    
    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∞–π–º–∏–Ω–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–º–µ—â–µ–Ω–∏–µ
    if offset > 0:
        transcript = adjust_srt_timings(transcript, offset_seconds=offset, index_offset=0)
    
    return transcript


async def transcribe_audio_chunk_async(
    audio_path: str, 
    chunk_num: int,
    total_chunks: int,
    async_client: AsyncOpenAI, 
    offset: float = 0,
    cache_dir: str = None
) -> Tuple[int, str]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API
    –ö—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (–Ω–æ–º–µ—Ä_—á–∞–Ω–∫–∞, SRT_–∫–æ–Ω—Ç–µ–Ω—Ç)
    """
    import time
    start_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω cache_dir
    cache_file = None
    if cache_dir:
        cache_file = os.path.join(cache_dir, f"chunk_{chunk_num}_raw.srt")
        if os.path.exists(cache_file):
            print(f"   üíæ –ß–∞–Ω–∫ {chunk_num}/{total_chunks}: –∑–∞–≥—Ä—É–∂–∞—é –∏–∑ –∫—ç—à–∞ {cache_file}", flush=True)
            with open(cache_file, 'r', encoding='utf-8') as f:
                transcript = f.read()
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∞–π–º–∏–Ω–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–º–µ—â–µ–Ω–∏–µ
            if offset > 0:
                transcript = adjust_srt_timings(transcript, offset_seconds=offset, index_offset=0)
            
            print(f"   ‚úÖ –ß–∞–Ω–∫ {chunk_num} –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –∫—ç—à–∞ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ!", flush=True)
            return (chunk_num, transcript)
    
    file_size = os.path.getsize(audio_path)
    duration_minutes = get_audio_duration(audio_path) / 60
    estimated_time = duration_minutes * 0.3
    
    print(f"   üì§ –ß–∞–Ω–∫ {chunk_num}/{total_chunks}: –æ—Ç–ø—Ä–∞–≤–ª—è—é {file_size / 1024 / 1024:.2f}MB (~{duration_minutes:.1f} –º–∏–Ω) –≤ Whisper API...", flush=True)
    print(f"      ‚è≥ –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: ~{estimated_time:.0f} —Å–µ–∫", flush=True)
    
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        with open(audio_path, 'rb') as audio_file:
            file_content = audio_file.read()
        
        # –°–æ–∑–¥–∞–µ–º file-like –æ–±—ä–µ–∫—Ç –¥–ª—è async API
        from io import BytesIO
        audio_file_obj = BytesIO(file_content)
        audio_file_obj.name = os.path.basename(audio_path)
        
        # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ asyncio.wait_for –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —Ç–∞–π–º–∞—É—Ç–∞
        async def do_transcription():
            return await async_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file_obj,
                response_format="srt",
                language="ru",
                timeout=1200.0
            )
        
        # –ñ–¥–µ–º —Å —Ç–∞–π–º–∞—É—Ç–æ–º 25 –º–∏–Ω—É—Ç (–º–∞–∫—Å–∏–º—É–º –¥–ª—è —á–∞–Ω–∫–∞)
        transcript = await asyncio.wait_for(do_transcription(), timeout=1500.0)
        
        elapsed_time = time.time() - start_time
        print(f"   ‚úÖ –ß–∞–Ω–∫ {chunk_num}/{total_chunks} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {elapsed_time:.0f} —Å–µ–∫!", flush=True)
        
        # –°–û–•–†–ê–ù–Ø–ï–ú –í –ö–≠–® –ø–µ—Ä–µ–¥ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–æ–π (—Å–æ—Ö—Ä–∞–Ω—è–µ–º raw –±–µ–∑ offset)
        if cache_file:
            os.makedirs(cache_dir, exist_ok=True)
            with open(cache_file, 'w', encoding='utf-8') as f:
                f.write(transcript)
            print(f"   üíæ –ß–∞–Ω–∫ {chunk_num} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∫—ç—à: {cache_file}", flush=True)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∞–π–º–∏–Ω–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–º–µ—â–µ–Ω–∏–µ (–∏–Ω–¥–µ–∫—Å—ã –ø–µ—Ä–µ–Ω—É–º–µ—Ä—É–µ–º –ø–æ–∑–∂–µ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏)
        if offset > 0:
            transcript = adjust_srt_timings(transcript, offset_seconds=offset, index_offset=0)
        
        return (chunk_num, transcript)
    
    except asyncio.TimeoutError:
        print(f"   ‚ùå –ß–∞–Ω–∫ {chunk_num}/{total_chunks} –ø—Ä–µ–≤—ã—Å–∏–ª —Ç–∞–π–º–∞—É—Ç (25 –º–∏–Ω—É—Ç)!", flush=True)
        print(f"   üí° –í–æ–∑–º–æ–∂–Ω–æ Whisper API –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ", flush=True)
        raise Exception(f"Timeout –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ {chunk_num}")
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ —á–∞–Ω–∫–µ {chunk_num}/{total_chunks}: {type(e).__name__}: {e}", flush=True)
        raise


def adjust_srt_timings(srt_content: str, offset_seconds: float, index_offset: int = 0) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ –∫–æ –≤—Å–µ–º —Ç–∞–π–º–∏–Ω–≥–∞–º –≤ SRT –∏ –ø–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã
    offset_seconds: —Å–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    index_offset: —Å–º–µ—â–µ–Ω–∏–µ –¥–ª—è –∏–Ω–¥–µ–∫—Å–æ–≤ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (–¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏ —Å–∫–ª–µ–π–∫–µ)
    """
    from datetime import timedelta
    
    def add_offset(time_str: str) -> str:
        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM:SS,mmm
        h, m, s_ms = time_str.split(':')
        s, ms = s_ms.split(',')
        
        # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å float
        total_seconds = float(h) * 3600 + float(m) * 60 + float(s) + float(ms) / 1000.0
        total_seconds += offset_seconds
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º
        hours = int(total_seconds // 3600)
        minutes = int((total_seconds % 3600) // 60)
        seconds = total_seconds % 60
        secs = int(seconds)
        milliseconds = int(round((seconds - secs) * 1000))
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è –∫–æ–≥–¥–∞ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –æ–∫—Ä—É–≥–ª–∏–ª–∏—Å—å –¥–æ 1000
        if milliseconds >= 1000:
            milliseconds = 0
            secs += 1
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
    
    lines = srt_content.split('\n')
    adjusted_lines = []
    
    for line in lines:
        line_stripped = line.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –∏–Ω–¥–µ–∫—Å —Å—É–±—Ç–∏—Ç—Ä–∞ (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
        if line_stripped.isdigit():
            # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å
            new_index = int(line_stripped) + index_offset
            adjusted_lines.append(str(new_index))
        elif '-->' in line:
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç–∞–π–º–∏–Ω–≥
            start, end = line.split(' --> ')
            start = add_offset(start.strip())
            end = add_offset(end.strip())
            adjusted_lines.append(f"{start} --> {end}")
        else:
            # –û—Å—Ç–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∫–∞–∫ –µ—Å—Ç—å (–≤–∫–ª—é—á–∞—è –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏!)
            adjusted_lines.append(line)
    
    return '\n'.join(adjusted_lines)


async def transcribe_audio_async(audio_paths: List[str], api_key: str, sequential: bool = True, cache_dir: str = None) -> str:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API
    sequential: –µ—Å–ª–∏ True - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–Ω–∞–¥–µ–∂–Ω–µ–µ), –µ—Å–ª–∏ False - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–±—ã—Å—Ç—Ä–µ–µ –Ω–æ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ)
    cache_dir: –ø–∞–ø–∫–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤ (—á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç
    """
    if len(audio_paths) == 1:
        # –û–¥–∏–Ω —Ñ–∞–π–ª - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é (–ø—Ä–æ—â–µ)
        print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API...", flush=True)
        sync_client = OpenAI(api_key=api_key, timeout=1200.0)
        transcript = transcribe_audio_chunk(audio_paths[0], sync_client)
        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞", flush=True)
        return transcript
    
    if sequential:
        # –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê - –Ω–∞–¥–µ–∂–Ω–µ–µ –¥–ª—è Whisper API
        print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API ({len(audio_paths)} —á–∞—Å—Ç–µ–π –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û)...", flush=True)
        print(f"   üí° –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–¥–µ–∂–Ω–µ–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤", flush=True)
        
        if cache_dir:
            os.makedirs(cache_dir, exist_ok=True)
            print(f"   üíæ –ö—ç—à —á–∞–Ω–∫–æ–≤: {cache_dir}", flush=True)
        
        async_client = AsyncOpenAI(api_key=api_key, timeout=1200.0)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
        offsets = [0]
        for audio_path in audio_paths[:-1]:
            duration = get_audio_duration(audio_path)
            offsets.append(offsets[-1] + duration)
        
        all_transcripts = []
        
        for i, (audio_path, offset) in enumerate(zip(audio_paths, offsets), 1):
            print(f"\nüìç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞–Ω–∫ {i}/{len(audio_paths)}...", flush=True)
            
            # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π (–∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞) —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API
            if i > 1:
                pause_seconds = 15
                print(f"   ‚è∏Ô∏è  –ü–∞—É–∑–∞ {pause_seconds} —Å–µ–∫ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å Whisper API)...", flush=True)
                await asyncio.sleep(pause_seconds)
            
            try:
                chunk_num, transcript = await transcribe_audio_chunk_async(
                    audio_path=audio_path,
                    chunk_num=i,
                    total_chunks=len(audio_paths),
                    async_client=async_client,
                    offset=offset,
                    cache_dir=cache_dir
                )
                all_transcripts.append((chunk_num, transcript))
                print(f"   ‚úÖ –ß–∞–Ω–∫ {i} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!", flush=True)
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ {i}: {e}", flush=True)
                print(f"   üîÑ –ü—Ä–æ–±—É—é –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ 20 —Å–µ–∫—É–Ω–¥...", flush=True)
                
                # Retry –æ–¥–∏–Ω —Ä–∞–∑ —Å –±–æ–ª—å—à–µ–π –ø–∞—É–∑–æ–π
                try:
                    await asyncio.sleep(20)
                    print(f"   üì§ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–∞–Ω–∫–∞ {i}...", flush=True)
                    chunk_num, transcript = await transcribe_audio_chunk_async(
                        audio_path=audio_path,
                        chunk_num=i,
                        total_chunks=len(audio_paths),
                        async_client=async_client,
                        offset=offset
                    )
                    all_transcripts.append((chunk_num, transcript))
                    print(f"   ‚úÖ –ß–∞–Ω–∫ {i} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø–æ—Å–ª–µ retry!", flush=True)
                except Exception as e2:
                    print(f"   ‚ùå –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e2}", flush=True)
                    print(f"   ‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞—é —ç—Ç–æ—Ç —á–∞–Ω–∫, –ø—Ä–æ–¥–æ–ª–∂–∞—é —Å–æ —Å–ª–µ–¥—É—é—â–∏–º...", flush=True)
                    continue
        
        if not all_transcripts:
            raise Exception("–í—Å–µ —á–∞–Ω–∫–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π!")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüîó –û–±—ä–µ–¥–∏–Ω—è—é {len(all_transcripts)} —É—Å–ø–µ—à–Ω—ã—Ö —á–∞–Ω–∫–æ–≤...", flush=True)
        
        all_transcripts.sort(key=lambda x: x[0])
        index_offset = 0
        combined_transcripts = []
        
        for chunk_num, transcript in all_transcripts:
            subtitle_count = transcript.strip().count('\n\n') + 1 if transcript.strip() else 0
            
            if chunk_num > 1 and index_offset > 0:
                adjusted_transcript = adjust_srt_timings(transcript, offset_seconds=0, index_offset=index_offset)
            else:
                adjusted_transcript = transcript
            
            index_offset += subtitle_count
            combined_transcripts.append(adjusted_transcript)
            print(f"   ‚úì –ß–∞–Ω–∫ {chunk_num}: {subtitle_count} —Å—É–±—Ç–∏—Ç—Ä–æ–≤", flush=True)
        
        combined = '\n\n'.join(combined_transcripts)
        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤—Å–µ—Ö {len(audio_paths)} —á–∞—Å—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–≤—Å–µ–≥–æ {index_offset} —Å—É–±—Ç–∏—Ç—Ä–æ–≤)!", flush=True)
        return combined
    
    # –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤)
    print(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API ({len(audio_paths)} —á–∞—Å—Ç–µ–π –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û)...", flush=True)
    
    # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
    async_client = AsyncOpenAI(api_key=api_key, timeout=1200.0)
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
    offsets = [0]
    for audio_path in audio_paths[:-1]:
        duration = get_audio_duration(audio_path)
        offsets.append(offsets[-1] + duration)
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
    tasks = []
    for i, (audio_path, offset) in enumerate(zip(audio_paths, offsets), 1):
        task = transcribe_audio_chunk_async(
            audio_path=audio_path,
            chunk_num=i,
            total_chunks=len(audio_paths),
            async_client=async_client,
            offset=offset
        )
        tasks.append(task)
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é {len(audio_paths)} —á–∞–Ω–∫–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ...", flush=True)
    print(f"   üí° –í—Å–µ —á–∞–Ω–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ - —ç—Ç–æ –Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ!", flush=True)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —á–∞—Å—Ç–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º return_exceptions=True —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–≤–∫–ª—é—á–∞—è –æ—à–∏–±–∫–∏)
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —É—Å–ø–µ—à–Ω—ã–µ –∏ –Ω–µ—É–¥–∞—á–Ω—ã–µ
    successful_results = []
    failed_chunks = []
    
    for i, result in enumerate(results, 1):
        if isinstance(result, Exception):
            failed_chunks.append(i)
            print(f"   ‚ùå –ß–∞–Ω–∫ {i} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {type(result).__name__}: {result}", flush=True)
        else:
            successful_results.append(result)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å
    if not successful_results:
        print(f"\n‚ùå –í—Å–µ {len(audio_paths)} —á–∞–Ω–∫–æ–≤ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π!", flush=True)
        raise Exception("–í—Å–µ —á–∞–Ω–∫–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–æ–π! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ - –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
    if failed_chunks:
        print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: {len(failed_chunks)} –∏–∑ {len(audio_paths)} —á–∞–Ω–∫–æ–≤ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {failed_chunks}", flush=True)
        print(f"   –ü—Ä–æ–¥–æ–ª–∂–∞—é —Å {len(successful_results)} —É—Å–ø–µ—à–Ω—ã–º–∏ —á–∞–Ω–∫–∞–º–∏...", flush=True)
        print(f"   üí° –°—É–±—Ç–∏—Ç—Ä—ã –±—É–¥—É—Ç –Ω–µ–ø–æ–ª–Ω—ã–º–∏ - –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ –ø–æ–∑–∂–µ", flush=True)
    
    # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏
    print(f"üîó –û–±—ä–µ–¥–∏–Ω—è—é {len(successful_results)} —á–∞–Ω–∫–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤...", flush=True)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —á–∞–Ω–∫–∞
    successful_results.sort(key=lambda x: x[0])
    
    all_transcripts = []
    index_offset = 0
    
    for chunk_num, transcript in successful_results:
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ —ç—Ç–æ–º —á–∞–Ω–∫–µ
        subtitle_count = transcript.strip().count('\n\n') + 1 if transcript.strip() else 0
        
        # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –Ω–∞—á–∏–Ω–∞—è —Å offset (–¥–ª—è —á–∞–Ω–∫–æ–≤ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ)
        if chunk_num > 1 and index_offset > 0:
            adjusted_transcript = adjust_srt_timings(transcript, offset_seconds=0, index_offset=index_offset)
        else:
            adjusted_transcript = transcript
        
        index_offset += subtitle_count
        all_transcripts.append(adjusted_transcript)
        print(f"   ‚úì –ß–∞–Ω–∫ {chunk_num}: {subtitle_count} —Å—É–±—Ç–∏—Ç—Ä–æ–≤", flush=True)
    
    combined = '\n\n'.join(all_transcripts)
    
    if failed_chunks:
        print(f"‚ö†Ô∏è  –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ß–ê–°–¢–ò–ß–ù–û: {len(successful_results)}/{len(audio_paths)} —á–∞–Ω–∫–æ–≤ (–≤—Å–µ–≥–æ {index_offset} —Å—É–±—Ç–∏—Ç—Ä–æ–≤)", flush=True)
    else:
        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤—Å–µ—Ö {len(audio_paths)} —á–∞—Å—Ç–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (–≤—Å–µ–≥–æ {index_offset} —Å—É–±—Ç–∏—Ç—Ä–æ–≤)!", flush=True)
    
    return combined


def transcribe_audio(audio_paths: List[str], client: OpenAI, cache_dir: str = None) -> str:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API
    –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
    cache_dir: –ø–∞–ø–∫–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç
    """
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ –∫–ª–∏–µ–Ω—Ç–∞
    api_key = client.api_key
    
    # –î–ª—è Windows: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É event loop
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    try:
        return asyncio.run(transcribe_audio_async(audio_paths, api_key, cache_dir=cache_dir))
    finally:
        # –ü–æ–¥–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –∑–∞–∫—Ä—ã—Ç–∏—è event loop –Ω–∞ Windows
        if sys.platform == 'win32':
            import warnings
            warnings.filterwarnings('ignore', category=RuntimeWarning, message='.*Event loop is closed.*')


def parse_srt(srt_content: str) -> List[SubtitleEntry]:
    """–ü–∞—Ä—Å–∏—Ç SRT –∫–æ–Ω—Ç–µ–Ω—Ç –≤ —Å–ø–∏—Å–æ–∫ SubtitleEntry"""
    entries = []
    blocks = srt_content.strip().split('\n\n')
    
    for block in blocks:
        lines = block.strip().split('\n')
        if len(lines) < 3:
            continue
        
        try:
            index = int(lines[0])
            timing = lines[1]
            text = '\n'.join(lines[2:])
            
            # –ü–∞—Ä—Å–∏–º —Ç–∞–π–º–∏–Ω–≥
            match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', timing)
            if match:
                start_time, end_time = match.groups()
                entries.append(SubtitleEntry(index, start_time, end_time, text))
        except (ValueError, IndexError):
            continue
    
    return entries


async def translate_batch_async(
    batch: List[SubtitleEntry], 
    batch_num: int, 
    total_batches: int,
    client: AsyncOpenAI, 
    model: str
) -> List[SubtitleEntry]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –æ–¥–∏–Ω –±–∞—Ç—á —Å—É–±—Ç–∏—Ç—Ä–æ–≤
    –ë–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏ (40-50) –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
    """
    print(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á {batch_num}/{total_batches} ({len(batch)} –∑–∞–ø–∏—Å–µ–π)...", flush=True)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
    prompt_lines = []
    for entry in batch:
        prompt_lines.append(f"[{entry.index}] {entry.text}")
    
    system_instruction = """You are a professional subtitle translator. Translate Russian subtitles into natural, conversational English.

CRITICAL RULES:
1. Translate ALL subtitles in the batch - NEVER skip any
2. Keep [number] format for each line
3. TRANSLATE COMPLETE TEXT - do NOT shorten or cut off translations
4. Each translation must contain ALL information from the original Russian text
5. Make translations natural and conversational but COMPLETE
6. IMPORTANT: Adjacent entries may be parts of ONE sentence split by timing - read context from neighbors to understand full meaning
7. But OUTPUT must have SAME number of [number] lines as input - one translation per entry
8. If an entry starts mid-sentence (no capital letter, continues from previous), translate it naturally while keeping same boundary split
9. Output ONLY translations in [number] text format - one line per subtitle

Example with split sentence:
Input:
[1] —á—Ç–æ–±—ã –º–æ–∂–Ω–æ
[2] –±—ã–ª–æ –ø—Ä–∏—Å–µ—Å—Ç—å –≤ –ø–µ—Ä–µ—Ä—ã–≤—ã, –¥–∞, –Ω–æ —ç—Ç–æ –≤—Å–µ —Ä–∞–≤–Ω–æ

Output:
[1] so you can
[2] sit during breaks, yes, but it's still

Example with complete sentence:
[1] –î–æ–±—Ä—ã–π –¥–µ–Ω—å, –∫–æ–ª–ª–µ–≥–∏! –°–µ–≥–æ–¥–Ω—è –º—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º –¥–∏–∑–∞–π–Ω —Ñ–∏—Ç–æ–±–∞—Ä–∞.
[2] –ù–∞—á–Ω–µ–º —Å –ø–ª–∞–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è.

Output:
[1] Good afternoon, colleagues! Today we're presenting the phytobar design.
[2] Let's start with the layout solution."""
    
    user_input = f"""<subtitles_to_translate>
{chr(10).join(prompt_lines)}
</subtitles_to_translate>

Translate all subtitles above into English. Output format: [number] translated_text"""
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Chat Completions API
        messages = [
            {"role": "system", "content": system_instruction},
            {"role": "user", "content": user_input}
        ]
        
        api_params = {
            "model": model,
            "messages": messages,
            "temperature": 0.7
        }
        
        # GPT-5 —Ç—Ä–µ–±—É–µ—Ç temperature=1 –∏ max_completion_tokens (–±–æ–ª—å—à–µ —Ç.–∫. reasoning —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è)
        if model.startswith('gpt-5') or model.startswith('o1') or model.startswith('o3'):
            api_params["temperature"] = 1.0
            api_params["max_completion_tokens"] = 16000  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è reasoning + –æ—Ç–≤–µ—Ç
        else:
            api_params["max_tokens"] = 4000
        
        response = await client.chat.completions.create(**api_params)
        
        translated_text = response.choices[0].message.content
        if translated_text is None:
            translated_text = ""
        translated_text = translated_text.strip()
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        translated_lines = translated_text.split('\n')
        translation_map = {}
        
        for line in translated_lines:
            match = re.match(r'\[(\d+)\]\s*(.+)', line.strip())
            if match:
                idx, text = match.groups()
                translation_map[int(idx)] = text.strip()
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ —Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        translated_batch = []
        untranslated = []
        
        for entry in batch:
            translated_text = translation_map.get(entry.index)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–µ—Ä–µ–≤–æ–¥ –ø–æ–ª—É—á–µ–Ω –ò –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É
            if translated_text and not re.search(r'[–ê-–Ø–∞-—è–Å—ë]', translated_text):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∫ –µ—Å—Ç—å (—Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –±—É–¥–µ—Ç –≤ post-processing)
                translated_batch.append(
                    SubtitleEntry(entry.index, entry.start_time, entry.end_time, translated_text)
                )
            else:
                # –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É - –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ –ø–æ–º–µ—á–∞–µ–º
                translated_batch.append(entry)
                untranslated.append(entry.index)
        
        if untranslated:
            print(f"   ‚ö†Ô∏è  –ë–∞—Ç—á {batch_num}: –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ {len(untranslated)} –∑–∞–ø–∏—Å–µ–π: {untranslated[:5]}{'...' if len(untranslated) > 5 else ''}", flush=True)
        else:
            print(f"   ‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches} –∑–∞–≤–µ—Ä—à–µ–Ω", flush=True)
        
        return translated_batch
    
    except Exception as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}: {e}", flush=True)
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
        return batch


async def translate_subtitles_async(entries: List[SubtitleEntry], api_key: str, model: str = "gpt-4o-mini") -> List[SubtitleEntry]:
    """
    –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∏ —É–ª—É—á—à–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã —á–µ—Ä–µ–∑ GPT –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –±–∞—Ç—á–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
    """
    print(f"üåê –ü–µ—Ä–µ–≤–æ–∂—É –∏ —É–ª—É—á—à–∞—é —Å—É–±—Ç–∏—Ç—Ä—ã —á–µ—Ä–µ–∑ {model} (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)...", flush=True)
    
    # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
    async_client = AsyncOpenAI(api_key=api_key)
    
    batch_size = 40  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞!
    total_batches = (len(entries) + batch_size - 1) // batch_size
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö –±–∞—Ç—á–µ–π
    tasks = []
    for i in range(0, len(entries), batch_size):
        batch = entries[i:i + batch_size]
        batch_num = i // batch_size + 1
        task = translate_batch_async(batch, batch_num, total_batches, async_client, model)
        tasks.append(task)
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é {total_batches} –±–∞—Ç—á–µ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...", flush=True)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(*tasks)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    translated_entries = []
    for batch_result in results:
        translated_entries.extend(batch_result)
    
    # –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê: —Å–Ω–∞—á–∞–ª–∞ —É–±–µ–¥–∏–º—Å—è —á—Ç–æ –≤—Å–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ, –ü–û–¢–û–ú –¥–µ–ª–∞–µ–º post-processing
    print(f"üîç –ü—Ä–æ–≤–µ—Ä—è—é –∫–∞—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–≤–æ–¥–∞...", flush=True)
    untranslated_count = sum(1 for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text))
    
    # RETRY LOGIC - –¥–µ–ª–∞–µ–º –î–û post-processing —á—Ç–æ–±—ã –∏–Ω–¥–µ–∫—Å—ã –Ω–µ –º–µ–Ω—è–ª–∏—Å—å
    retry_round = 0
    max_retries = 2
    
    while untranslated_count > 0 and retry_round < max_retries:
        retry_round += 1
        print(f"\n‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {untranslated_count} –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π", flush=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å –∏—Ö –∏–Ω–¥–µ–∫—Å–∞–º–∏
        to_retry = [e for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text)]
        untranslated_indices = [e.index for e in to_retry]
        print(f"   üìã –ò–Ω–¥–µ–∫—Å—ã: {untranslated_indices[:10]}{'...' if len(untranslated_indices) > 10 else ''}", flush=True)
        print(f"   üîÑ –ó–∞–ø—É—Å–∫–∞—é retry #{retry_round}/{max_retries} (–±–∞—Ç—á–∏ –ø–æ 20)...", flush=True)
        
        # –ü–æ–≤—Ç–æ—Ä–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏–º –º–µ–Ω—å—à–∏–º–∏ –±–∞—Ç—á–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–π –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏
        retry_batch_size = 20
        retry_tasks = []
        for i in range(0, len(to_retry), retry_batch_size):
            retry_batch = to_retry[i:i + retry_batch_size]
            batch_num = i // retry_batch_size + 1
            total_retry_batches = (len(to_retry) + retry_batch_size - 1) // retry_batch_size
            task = translate_batch_async(retry_batch, batch_num, total_retry_batches, async_client, model)
            retry_tasks.append(task)
        
        retry_results = await asyncio.gather(*retry_tasks)
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ –∏–Ω–¥–µ–∫—Å—É
        retry_map = {}
        for batch_result in retry_results:
            for entry in batch_result:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ (–±–µ–∑ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã)
                if not re.search(r'[–ê-–Ø–∞-—è–Å—ë]', entry.text):
                    retry_map[entry.index] = entry
        
        # –ó–∞–º–µ–Ω—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Å–ø–∏—Å–∫–µ —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ
        updated_entries = []
        for entry in translated_entries:
            if entry.index in retry_map:
                updated_entries.append(retry_map[entry.index])
            else:
                updated_entries.append(entry)
        translated_entries = updated_entries
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        prev_untranslated = untranslated_count
        untranslated_count = sum(1 for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text))
        
        if untranslated_count == 0:
            print(f"   ‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –ø–æ—Å–ª–µ retry #{retry_round}!", flush=True)
            break
        elif untranslated_count < prev_untranslated:
            print(f"   üìâ –ü—Ä–æ–≥—Ä–µ—Å—Å: {prev_untranslated} ‚Üí {untranslated_count} –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö", flush=True)
        else:
            print(f"   ‚ö†Ô∏è  –ù–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: –≤—Å–µ –µ—â–µ {untranslated_count} –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö", flush=True)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    final_untranslated = sum(1 for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text))
    if final_untranslated > 0:
        print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: {final_untranslated} –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞–ª–∏—Å—å –Ω–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º–∏ –ø–æ—Å–ª–µ {retry_round} retry", flush=True)
        failed_indices = [e.index for e in translated_entries if re.search(r'[–ê-–Ø–∞-—è–Å—ë]', e.text)]
        print(f"   –ù–µ–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã: {failed_indices}", flush=True)
        print(f"   üí° –≠—Ç–∏ –∑–∞–ø–∏—Å–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ", flush=True)
    else:
        print(f"‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã!", flush=True)
    
    # POST-PROCESSING: —Ä–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã (>2 —Å—Ç—Ä–æ–∫)
    # –î–µ–ª–∏–º —Å–ª–æ–≤–∞ –ø–æ–ø–æ–ª–∞–º + –≤—Ä–µ–º—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø–æ–∫–∞ <= 2 —Å—Ç—Ä–æ–∫)
    print(f"\nüìê Post-processing: —Ä–∞–∑–±–∏–≤–∞—é –¥–ª–∏–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ —á–∞—Å—Ç–∏ (–º–∞–∫—Å 2 —Å—Ç—Ä–æ–∫–∏)...", flush=True)
    final_entries = []
    for entry in translated_entries:
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –¥–µ–ª–∏–º –µ—Å–ª–∏ > 2 —Å—Ç—Ä–æ–∫
        parts = split_subtitle_entry(entry, max_lines=2)
        final_entries.extend(parts)
    
    print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(entries)} ‚Üí {len(final_entries)} –∑–∞–ø–∏—Å–µ–π (–ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–ª–∏–Ω–Ω—ã—Ö)", flush=True)
    return final_entries


def translate_subtitles(entries: List[SubtitleEntry], api_key: str, model: str = "gpt-4o-mini") -> List[SubtitleEntry]:
    """
    –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
    """
    # –î–ª—è Windows: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏–∫—É event loop
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    try:
        return asyncio.run(translate_subtitles_async(entries, api_key, model))
    finally:
        # –ü–æ–¥–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –∑–∞–∫—Ä—ã—Ç–∏—è event loop –Ω–∞ Windows
        if sys.platform == 'win32':
            import warnings
            warnings.filterwarnings('ignore', category=RuntimeWarning, message='.*Event loop is closed.*')


def save_srt(entries: List[SubtitleEntry], output_path: str) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –≤ SRT —Ñ–∞–π–ª"""
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å—É–±—Ç–∏—Ç—Ä—ã –≤ {output_path}...")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(str(entry) + '\n')
    
    print(f"‚úÖ –°—É–±—Ç–∏—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")


def burn_subtitles(video_path: str, srt_path: str, output_path: str) -> None:
    """–í—à–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –≤ –≤–∏–¥–µ–æ (hardcoded)"""
    print(f"üé¨ –í—à–∏–≤–∞—é —Å—É–±—Ç–∏—Ç—Ä—ã –≤ –≤–∏–¥–µ–æ...")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏ –¥–ª—è ffmpeg (–æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è Windows)
    srt_path_escaped = srt_path.replace('\\', '/').replace(':', '\\:')
    
    cmd = [
        FFMPEG_PATH, '-i', video_path,
        '-vf', f"subtitles='{srt_path_escaped}':force_style='FontName=Arial,FontSize=12,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,BackColour=&H80404040,BorderStyle=3,Outline=1,Shadow=0,MarginV=10'",
        '-c:a', 'copy',  # –∫–æ–ø–∏—Ä—É–µ–º –∞—É–¥–∏–æ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        '-y',
        output_path
    ]
    
    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"‚úÖ –í–∏–¥–µ–æ —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏: {output_path}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—à–∏–≤–∞–Ω–∏–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤: {e.stderr.decode()}")
        raise


def main():
    parser = argparse.ArgumentParser(
        description='–£–ª—É—á—à–µ–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ: —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —á–µ—Ä–µ–∑ Whisper + –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ GPT',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python subtitle_improver.py video.mp4
  python subtitle_improver.py video.mp4 --model gpt-4o
  python subtitle_improver.py video.mp4 --skip-burn

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
  OPENAI_API_KEY - –≤–∞—à API –∫–ª—é—á OpenAI (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        """
    )
    
    parser.add_argument('video', help='–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É')
    parser.add_argument('--model', 
                        choices=['gpt-4o-mini', 'gpt-4o', 'gpt-5'],
                        default='gpt-4o',
                        help='–ú–æ–¥–µ–ª—å GPT –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: gpt-4o, –º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –∑–∞–¥–∞—Ç—å –≤ .env —Ñ–∞–π–ª–µ)')
    parser.add_argument('--skip-burn', action='store_true',
                        help='–ù–µ –≤—à–∏–≤–∞—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –≤ –≤–∏–¥–µ–æ, —Ç–æ–ª—å–∫–æ —Å–æ–∑–¥–∞—Ç—å .srt —Ñ–∞–π–ª')
    parser.add_argument('--force-retranscribe', action='store_true',
                        help='–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—ç—à —á–∞–Ω–∫–æ–≤ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∑–∞–Ω–æ–≤–æ')
    parser.add_argument('--step', 
                        choices=['all', 'transcribe', 'translate', 'burn'],
                        default='all',
                        help='–ö–∞–∫–æ–π —ç—Ç–∞–ø –≤—ã–ø–æ–ª–Ω–∏—Ç—å: all (–≤—Å–µ), transcribe (—Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è), translate (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥), burn (—Ç–æ–ª—å–∫–æ –≤—à–∏–≤–∞–Ω–∏–µ)')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY")
        print()
        print("   –†–µ—à–µ–Ω–∏–µ 1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): –°–æ–∑–¥–∞–π—Ç–µ .env —Ñ–∞–π–ª")
        print("   1. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ env.example –≤ .env")
        print("   2. –û—Ç–∫—Ä–æ–π—Ç–µ .env –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à API –∫–ª—é—á")
        print()
        print("   –†–µ—à–µ–Ω–∏–µ 2: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        print("   PowerShell: $env:OPENAI_API_KEY=\"your-api-key\"")
        print("   CMD:        set OPENAI_API_KEY=your-api-key")
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å: –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤, –∏–∑ .env –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    model = args.model or os.environ.get('GPT_MODEL', 'gpt-4o-mini')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ
    video_path = Path(args.video)
    if not video_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.video}")
        sys.exit(1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Ç–∏ –∫ ffmpeg –∏ ffprobe (—Ç–æ–ª—å–∫–æ –¥–ª—è —ç—Ç–∞–ø–æ–≤ –∫–æ—Ç–æ—Ä—ã–º –æ–Ω–∏ –Ω—É–∂–Ω—ã)
    if args.step in ['all', 'transcribe', 'burn']:
        global FFMPEG_PATH, FFPROBE_PATH
        
        FFMPEG_PATH = find_ffmpeg()
        FFPROBE_PATH = find_ffprobe()
        
        if not FFMPEG_PATH or not FFPROBE_PATH:
            print("‚ùå –û—à–∏–±–∫–∞: ffmpeg/ffprobe –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            print()
            print("   üì• –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ffmpeg –æ–¥–Ω–∏–º –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤:")
            print()
            print("   –°–ø–æ—Å–æ–± 1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è): Chocolatey")
            print("   1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Chocolatey: https://chocolatey.org/install")
            print("   2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ PowerShell –æ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
            print("   3. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: choco install ffmpeg")
            print()
            print("   –°–ø–æ—Å–æ–± 2: Scoop")
            print("   1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Scoop: https://scoop.sh")
            print("   2. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: scoop install ffmpeg")
            print()
            print("   –°–ø–æ—Å–æ–± 3: –í—Ä—É—á–Ω—É—é")
            print("   1. –°–∫–∞—á–∞–π—Ç–µ: https://www.gyan.dev/ffmpeg/builds/")
            print("   2. –†–∞—Å–ø–∞–∫—É–π—Ç–µ –≤ C:\\ffmpeg")
            print("   3. –î–æ–±–∞–≤—å—Ç–µ C:\\ffmpeg\\bin –≤ PATH")
            print()
            print("   üìç –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∏—Å–∫–∞–ª–∞ ffmpeg –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –º–µ—Å—Ç–∞—Ö:")
            print("      - –°–∏—Å—Ç–µ–º–Ω—ã–π PATH")
            print("      - C:\\ffmpeg\\bin\\")
            print("      - C:\\Program Files\\ffmpeg\\bin\\")
            print(f"      - {os.path.expanduser('~\\ffmpeg\\bin\\')}")
            print("      - C:\\ProgramData\\chocolatey\\bin\\")
            print(f"      - {os.path.expanduser('~\\scoop\\apps\\ffmpeg\\')}")
            print(f"      - {os.getcwd()} (—Ç–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞)")
            print()
            sys.exit(1)
        
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω ffmpeg: {FFMPEG_PATH}")
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω ffprobe: {FFPROBE_PATH}")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º OpenAI –∫–ª–∏–µ–Ω—Ç —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
    client = OpenAI(api_key=api_key, timeout=1200.0)  # 20 –º–∏–Ω—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    base_name = video_path.stem
    outputs_dir = video_path.parent / "outputs" / base_name
    outputs_dir.mkdir(parents=True, exist_ok=True)
    
    # –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ—Ä–Ω–µ –ø–∞–ø–∫–∏ –≤–∏–¥–µ–æ
    russian_srt = outputs_dir / "russian.srt"
    
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É —Å timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = outputs_dir / f"run_{timestamp}"
    run_dir.mkdir(parents=True, exist_ok=True)
    
    output_srt = run_dir / "improved.srt"
    output_video = run_dir / "subtitled.mp4"
    
    step = args.step
    
    print(f"üìÅ –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {run_dir}", flush=True)
    
    print(f"\n{'='*60}", flush=True)
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ: {video_path.name}", flush=True)
    print(f"{'='*60}\n", flush=True)
    
    try:
        # ========================================
        # –≠–¢–ê–ü 1: –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø (Whisper)
        # ========================================
        if step in ['all', 'transcribe']:
            if russian_srt.exists():
                print(f"‚ÑπÔ∏è  –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç: {russian_srt}")
                print(f"   –£–¥–∞–ª–∏—Ç–µ —Ñ–∞–π–ª –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ—Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å")
            else:
                # –®–∞–≥ 1: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ
                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_audio:
                    audio_path = tmp_audio.name
                
                extract_audio(str(video_path), audio_path)
                
                # –®–∞–≥ 2: –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                audio_chunks = split_audio(audio_path)
                
                # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∫—ç—à–∞ —á–∞–Ω–∫–æ–≤
                chunks_cache_dir = outputs_dir / "chunks"
                
                # –ï—Å–ª–∏ --force-retranscribe, —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –∫—ç—à
                if args.force_retranscribe and chunks_cache_dir.exists():
                    import shutil
                    shutil.rmtree(chunks_cache_dir)
                    print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –∫—ç—à —á–∞–Ω–∫–æ–≤, –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–ª–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è", flush=True)
                
                # –®–∞–≥ 3: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ Whisper (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç SRT)
                # –ö—ç—à–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
                srt_content = transcribe_audio(audio_chunks, client, cache_dir=str(chunks_cache_dir))
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã
                for chunk in audio_chunks:
                    if os.path.exists(chunk):
                        os.unlink(chunk)
                if audio_path not in audio_chunks and os.path.exists(audio_path):
                    os.unlink(audio_path)
                
                # Debug: —Å–æ—Ö—Ä–∞–Ω—è–µ–º RAW SRT –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                temp_raw_path = str(russian_srt).replace('.srt', '_raw_debug.srt')
                with open(temp_raw_path, 'w', encoding='utf-8') as f:
                    f.write(srt_content)
                print(f"üêõ Debug: RAW SRT —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {temp_raw_path}", flush=True)
                
                # –ü–∞—Ä—Å–∏–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã
                print(f"üìù –ü–∞—Ä—Å–∏–Ω–≥ —Å—É–±—Ç–∏—Ç—Ä–æ–≤...", flush=True)
                
                # Debug: —Å–∫–æ–ª—å–∫–æ –±–ª–æ–∫–æ–≤ –≤ raw SRT
                raw_blocks = srt_content.strip().split('\n\n')
                print(f"   üîç Raw SRT: {len(raw_blocks)} –±–ª–æ–∫–æ–≤, {len(srt_content)} —Å–∏–º–≤–æ–ª–æ–≤", flush=True)
                
                russian_entries = parse_srt(srt_content)
                print(f"   ‚úÖ –†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ: {len(russian_entries)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {len(raw_blocks)} –±–ª–æ–∫–æ–≤", flush=True)
                
                if len(russian_entries) < len(raw_blocks):
                    print(f"   ‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ü–æ—Ç–µ—Ä—è–Ω–æ {len(raw_blocks) - len(russian_entries)} –±–ª–æ–∫–æ–≤ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ!", flush=True)
                
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã –≤ {russian_srt}...", flush=True)
                save_srt(russian_entries, str(russian_srt))
                print(f"‚úÖ –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {len(russian_entries)} –∑–∞–ø–∏—Å–µ–π", flush=True)
        
        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è - –≤—ã—Ö–æ–¥–∏–º
        if step == 'transcribe':
            print(f"\n{'='*60}", flush=True)
            print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", flush=True)
            print(f"{'='*60}", flush=True)
            print(f"üìÑ –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {russian_srt.relative_to(video_path.parent)}", flush=True)
            print(f"\n–î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:", flush=True)
            print(f"  python subtitle_improver.py {args.video} --step translate\n", flush=True)
            return
        
        # ========================================
        # –≠–¢–ê–ü 2: –ü–ï–†–ï–í–û–î (GPT)
        # ========================================
        if step in ['all', 'translate']:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã
            if not russian_srt.exists():
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ (–¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏)
                old_russian_srt = video_path.parent / f"{base_name}_russian.srt"
                if old_russian_srt.exists():
                    print(f"‚ÑπÔ∏è  –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ø–µ—Ä–µ–º–µ—â–∞—é –≤ –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...", flush=True)
                    russian_srt.parent.mkdir(parents=True, exist_ok=True)
                    old_russian_srt.rename(russian_srt)
                    print(f"‚úÖ –§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤: {russian_srt.relative_to(video_path.parent)}", flush=True)
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {russian_srt} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    print(f"   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python subtitle_improver.py {args.video} --step transcribe")
                    sys.exit(1)
            
            print(f"üìñ –ó–∞–≥—Ä—É–∂–∞—é —Ä—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ {russian_srt}...", flush=True)
            with open(russian_srt, 'r', encoding='utf-8') as f:
                srt_content = f.read()
            
            # –ü–∞—Ä—Å–∏–º SRT
            print(f"üìù –ü–∞—Ä—Å–∏–Ω–≥ —Å—É–±—Ç–∏—Ç—Ä–æ–≤...", flush=True)
            russian_entries = parse_srt(srt_content)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(russian_entries)} –∑–∞–ø–∏—Å–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤", flush=True)
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —á–µ—Ä–µ–∑ GPT (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ!)
            translated_entries = translate_subtitles(russian_entries, api_key, model)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã
            save_srt(translated_entries, str(output_srt))
        
        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥ - –≤—ã—Ö–æ–¥–∏–º
        if step == 'translate':
            print(f"\n{'='*60}", flush=True)
            print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!", flush=True)
            print(f"{'='*60}", flush=True)
            print(f"üìÅ –ü–∞–ø–∫–∞: {run_dir.relative_to(video_path.parent)}", flush=True)
            print(f"üìÑ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {output_srt.name}", flush=True)
            print(f"\n–î–ª—è –≤—à–∏–≤–∞–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ:", flush=True)
            print(f"  python subtitle_improver.py {args.video} --step burn\n", flush=True)
            return
        
        # ========================================
        # –≠–¢–ê–ü 3: –í–®–ò–í–ê–ù–ò–ï (ffmpeg)
        # ========================================
        if step in ['all', 'burn']:
            # –î–ª—è burn –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π run —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏
            if step == 'burn' and not output_srt.exists():
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞–ø–∫—É run_* —Å improved.srt
                run_dirs = sorted(outputs_dir.glob("run_*/improved.srt"))
                if run_dirs:
                    latest_srt = run_dirs[-1]
                    print(f"üìñ –ò—Å–ø–æ–ª—å–∑—É—é —Å—É–±—Ç–∏—Ç—Ä—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞: {latest_srt.parent.name}", flush=True)
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É –¥–ª—è burn
                    output_srt = latest_srt  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
                    output_video = latest_srt.parent / "subtitled.mp4"
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—É–±—Ç–∏—Ç—Ä—ã")
                    print(f"   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python subtitle_improver.py {args.video} --step translate")
                    sys.exit(1)
            
            if args.skip_burn:
                print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞—é –≤—à–∏–≤–∞–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (--skip-burn)", flush=True)
            else:
                burn_subtitles(str(video_path), str(output_srt), str(output_video))
        
        # –ò—Ç–æ–≥–∏
        print(f"\n{'='*60}", flush=True)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", flush=True)
        print(f"{'='*60}", flush=True)
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {run_dir.relative_to(video_path.parent)}", flush=True)
        print(f"", flush=True)
        if russian_srt.exists():
            print(f"   üìÑ –†—É—Å—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {russian_srt.relative_to(video_path.parent)}", flush=True)
        if output_srt.exists():
            print(f"   üìÑ –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—É–±—Ç–∏—Ç—Ä—ã: {output_srt.relative_to(outputs_dir)}", flush=True)
        if not args.skip_burn and output_video.exists():
            print(f"   üé¨ –í–∏–¥–µ–æ —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏: {output_video.relative_to(outputs_dir)}", flush=True)
        print(f"\n", flush=True)
        
    except KeyboardInterrupt:
        print(f"\n\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

